{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step1: 了解公式\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "# step2: 开始代码 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解析\n",
    "这段代码实现了一个基础版的自注意力机制（self-attention）模型。\n",
    "\n",
    "以下是对代码逐行解读：\n",
    "1-3行:\n",
    "\n",
    "```python\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "```\n",
    "\n",
    "这些行导入了必要的Python库\n",
    "`math`库用于数学运算，\n",
    "\n",
    "`torch`是PyTorch库，它是一个机器学习库，用于深度学习模型的训练和推理。\n",
    "\n",
    "`torch.nn`是PyTorch的神经网络模块，提供了很多神经网络的层和常用的操作。\n",
    "\n",
    "5-6行:\n",
    "```python\n",
    "\n",
    "class SelfattentionV1(nn.Module):    \n",
    "    def __init__(self, hidden_dim: int = 728) -> None:\n",
    "```\n",
    "        \n",
    "这里定义了一个名为`SelfattentionV1`的类，该类继承自`nn.Module`，这是所有PyTorch神经网络模块的基类。\n",
    "\n",
    "类初始化函数`__init__`接受一个参数`hidden_dim`，用来指定隐藏层的维度，默认值为728。\n",
    "\n",
    "7行:\n",
    "```python        \n",
    "super().__init__()\n",
    "```\n",
    "\n",
    "这行代码调用了基类`nn.Module`的构造函数，是初始化操作的一个标准步骤。\n",
    "\n",
    "8行:\n",
    "```python        \n",
    "self.hidden_dim = hidden_dim\n",
    "```\n",
    "\n",
    "这行代码将传入的`hidden_dim`保存在类的成员变量中，供后续的代码使用。\n",
    "\n",
    "10-12行:\n",
    "```python        \n",
    "self.querry_proj = nn.Linear(hidden_dim, hidden_dim)        \n",
    "self.key_proj = nn.Linear(hidden_dim, hidden_dim)        \n",
    "self.value_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "```\n",
    "\n",
    "这里定义了三个线性层（也就是全连接层），分别用于计算查询（query）、键（key）和值（value）。\n",
    "\n",
    "每个线性层都将输入的维度从`hidden_dim`映射到`hidden_dim`，即不改变维度。\n",
    "\n",
    "14-15行:\n",
    "```python    \n",
    "def forward(self, x):        \n",
    "    #x shape is :(batch, size_len, hidden_dim)\n",
    "```\n",
    "\n",
    "定义了模型的前向传播函数`forward`，它接受一个输入张量`x`。\n",
    "\n",
    "`x`的形状预期为(batch_size, sequence_length, hidden_dim)。\n",
    "\n",
    "16-18行:\n",
    "```python        \n",
    "Q = self.querry_proj(x)        \n",
    "K = self.key_proj(x)        \n",
    "V = self.value_proj(x)        \n",
    "#Q K V shape is :(batch, size_len, hidden_dim)\n",
    "```\n",
    "\n",
    "这里利用之前定义的线性层对输入`x`进行变换，\n",
    "\n",
    "得到查询（Q），键（K）和值（V）。\n",
    "\n",
    "它们的形状没有改变，依然是(batch_size, sequence_length, hidden_dim)。\n",
    "\n",
    "21-23行:\n",
    "```python        \n",
    "# attention_value 是： （batch, seq, seq）        \n",
    "attention_value = torch.matmul(            Q, K.transpose(-1,-2)        )\n",
    "```\n",
    "\n",
    "这几行执行`Q`矩阵和`K`矩阵的转置后的矩阵乘法，得到注意力值(attention scores)。\n",
    "\n",
    "先使用`K.transpose(-1, -2)`将`K`的最后两个维度进行转置，以便与`Q`矩阵执行点积。\n",
    "\n",
    "通过矩阵乘法，计算了attention_value，其形状是\n",
    "\n",
    "(batch_size, sequence_length, sequence_length)。\n",
    "\n",
    "26-28行:\n",
    "```python        \n",
    "#attention_weight 是： （batch, seq, seq)        \n",
    "attention_weight = torch.softmaxattention_value / math.sqrt(self.hidden_dim),\n",
    "\n",
    "dim = -1        )        \n",
    "print(attention_weight)\n",
    "```\n",
    "\n",
    "这里对`attention_value`施加了缩放因子除以`hidden_dim`的平方根（来自“Attention Is All You Need”论文），\n",
    "\n",
    "用来减少计算query和key点积之后变量的方差，然后应用softmax函数，使得每一行的求和为1，得到注意力权重（attention weights）。\n",
    "\n",
    "最后，打印出注意力权重。注意力权重的形状未变，有利于下一步的加权和操作。\n",
    "\n",
    "31-32行:\n",
    "\n",
    "```python        \n",
    "# (batch, seq, hidden_dim)        \n",
    "output = torch.matmul(attention_weight, V)        \n",
    "return output\n",
    "```\n",
    "这里使用注意力权重加权求和值（V）。\n",
    "\n",
    "通过`torch.matmul(attention_weight, V)`执行矩阵乘法，计算加权的输出值。\n",
    "\n",
    "此时`output`的形状是(batch_size, sequence_length, hidden_dim)，\n",
    "\n",
    "与输入`x`形状相同。\n",
    "\n",
    "34-35行:\n",
    "```python\n",
    "X = torch.rand(3, 2, 4)\n",
    "self_att_net = SelfattentionV1(4)\n",
    "```\n",
    "这里创建了一个形状为(3, 2, 4)的随机张量X，即3个样本，每个样本2个序列长度，每个序列长度的特征维度为4。\n",
    "\n",
    "然后初始化一个隐藏维度为4的`SelfattentionV1`实例。\n",
    "\n",
    "36行:\n",
    "```python\n",
    "self_att_net(X)\n",
    "```\n",
    "\n",
    "最后将`X`作为输入传递给自注意力模型进行前向传播计算。\n",
    "\n",
    "综上所述，这段代码展示了自注意力机制的基础实现，\n",
    "\n",
    "如何将输入通过查询query、键key、值value变换，\n",
    "\n",
    "然后根据注意力权重计算输出。\n",
    "\n",
    "这种机制是许多现代神经网络架构（如Transformer）的基石。\n",
    "\n",
    "在实际应用中，可以在这个基础上添加诸如多头注意力、层归一化、残差连接等许多其他特性来增强模型性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基类nn.Module是什么？\n",
    "\n",
    "基类nn.Module是PyTorch中所有神经网络模块的基本类。当你创建一个新的神经网络模型时，你通常会通过继承nn.Module来实现你的模型。这个基类提供一些基础功能，比如跟踪模型中的层、参数、保存和加载模型等。\n",
    "\n",
    "什么是hidden_dim？他是怎么来定义的？默认值为什么为728？\n",
    "\n",
    "hidden_dim是隐藏单元的维度，它是一个超参数，用以定义模型内部层的大小或复杂度。在上文中，hidden_dim是通过类SelfattentionV1构造函数的参数传入的，即在创建类的对象实例时设定。默认值为728可能没有特别的原因，这可能是代码编写者根据经验设置的一个合理值，或许基于之前在具体数据集上的实验效果决定的。\n",
    "\n",
    "super是什么意思？怎么用的？\n",
    "\n",
    "super()函数用于调用基类的方法。在类的方法中调用super()会返回一个代理对象，这个对象能够引用基类的方法，这样就可以调用基类内部定义的方法而不会导致无限递归。在上文代码中的super().__init__()就是在调用nn.Module类的构造函数来正确初始化基类的内部状态。\n",
    "\n",
    "\n",
    "全连接层（Fully Connected Layer，也称为线性层）\n",
    "\n",
    "\n",
    "全连接层是一种最基本的神经网络层，也是在传统的多层感知机（Multi-Layer Perceptron, MLP）中广泛使用的层。在全连接层中，每个输入单元都与下一层的每个输出单元连接，每个连接都有一个相关的权重。mathematically，全连接层进行的操作可以表示为：\n",
    "\n",
    "[ \\text{output} = \\text{activation}(\\mathbf{W} \\cdot \\mathbf{input} + \\mathbf{b}) ]\n",
    "\n",
    "其中 (\\mathbf{W}) 是权重矩阵，(\\mathbf{b}) 是偏置向量，(\\text{activation}(\\cdot)) 是可选的激活函数。\n",
    "\n",
    "在PyTorch中，全连接层可以通过torch.nn.Linear类来实现，其中需要指定输入和输出的特征数量。例如，nn.Linear(10, 5)将创建一个从10个输入特征到5个输出特征的全连接层。\n",
    "\n",
    "什么是前向传播函数？\n",
    "\n",
    "前向传播函数forward是定义在nn.Module子类中的一个特殊方法，它规定了数据通过网络的方式。在模型训练或推理时，它会被自动调用。在这个函数中，你定义了模型的结构以及数据怎样流经这个结构。\n",
    "\n",
    "x的维度是怎么确定的？\n",
    "\n",
    "在上文代码的注释中提到，x的预期维度是(batch_size, sequence_length, hidden_dim)。这是由自注意力模型的输入形式决定的。batch_size是每次送入网络的样本数量， sequence_length是序列的长度（例如在处理文本数据时，这通常对应于一句话中的单词数），hidden_dim则是之前定义的隐藏层的维度。这个维度是在模型创建时，通过传入参数指定的，同时也与实际的数据输入相匹配。\n",
    "\n",
    "softmax的dim 是什么意思？怎么决定用什么？\n",
    "\n",
    "softmax函数是一种将向量的元素值转换成概率分布的函数。dim参数指定了在哪个维度上应用softmax。在上文中使用torch.softmax的时候，dim=-1意味着softmax会应用在最后一个维度上，正好是序列长度维度（在自注意力机制中，我们期望每个序列长度位置分数的softmax。由于batch和hidden_dim其他两个维度应保持不变，因此dim=-1保证了这一点。通常，我们在哪一个维度上想要获取概率分布，那个维度就会被设置为softmax函数的dim参数。\n",
    "\n",
    "\n",
    "维度 (d_k) 的计算\n",
    "在自注意力机制中，有时我们会遇到 (d_k) 这个变量，它通常指的是键（key）的维度，在缩放点积注意力计算中很重要，因为我们通常会将注意力分数除以 (\\sqrt{d_k}) 来稳定梯度。\n",
    "\n",
    "如果 (d_k) 没有明确定义，其取值通常与模型中的隐藏维度 hidden_dim 是一样的，因为在简化模型中，key的转换矩阵通常是正方形的，即它的输入和输出维度相同。但在更复杂的模型（例如Transformer模型）里，(d_k) 会根据模型超参数进行设置，尤其是在使用多头注意力时，每一个头的 (d_k) 可能会是隐藏维度除以头的数量。\n",
    "\n",
    "计算方式示例：如果模型的隐藏维度是256，并且使用8个头进行多头注意力，那么每个头的 (d_k) 可能就是 (256 / 8 = 32)。\n",
    "\n",
    "综上所述，(d_k) 的取值不是随意设定的，而是基于模型的构建和设计决策。全连接层的输出维度应该与模型或任务的要求相匹配。当使用全连接层作为注意力模块中的查询（query）、键（key）和值（value）的投影时，这些维度都应事先确定好。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4982, 0.5018],\n",
      "         [0.4974, 0.5026]],\n",
      "\n",
      "        [[0.5076, 0.4924],\n",
      "         [0.4842, 0.5158]],\n",
      "\n",
      "        [[0.4880, 0.5120],\n",
      "         [0.4834, 0.5166]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7893, -0.5008, -0.8059,  0.3949],\n",
       "         [-0.7893, -0.5010, -0.8060,  0.3950]],\n",
       "\n",
       "        [[-0.4251, -0.2737, -0.7517,  0.1666],\n",
       "         [-0.4272, -0.2621, -0.7536,  0.1595]],\n",
       "\n",
       "        [[-0.3438, -0.1748, -0.6979,  0.1224],\n",
       "         [-0.3446, -0.1775, -0.6989,  0.1233]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 第一重最简单代码\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfattentionV1(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 728) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.querry_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x shape is :(batch, size_len, hidden_dim)\n",
    "        Q = self.querry_proj(x)\n",
    "        K = self.key_proj(x)\n",
    "        V = self.value_proj(x)\n",
    "        #Q K V shape is :(batch, size_len, hidden_dim)\n",
    "\n",
    "\n",
    "        # attention_value 是： （batch, seq, seq）\n",
    "        attention_value = torch.matmul(\n",
    "            Q, K.transpose(-1,-2)\n",
    "        )\n",
    "\n",
    "        #attention_weight 是： （batch, seq, seq)\n",
    "        attention_weight = torch.softmax(\n",
    "            attention_value/ math.sqrt(self.hidden_dim),\n",
    "            dim = -1\n",
    "        )\n",
    "        print(attention_weight)\n",
    "\n",
    "        # (batch, seq, hidden_dim)\n",
    "        output = torch.matmul(attention_weight, V)\n",
    "        return output\n",
    "X = torch.rand(3, 2, 4)\n",
    "\n",
    "self_att_net = SelfattentionV1(4)\n",
    "self_att_net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5485, 0.4515],\n",
      "         [0.5281, 0.4719]],\n",
      "\n",
      "        [[0.4927, 0.5073],\n",
      "         [0.4922, 0.5078]],\n",
      "\n",
      "        [[0.4978, 0.5022],\n",
      "         [0.4841, 0.5159]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4405, -0.4308, -0.4967, -0.3142],\n",
       "         [ 0.4444, -0.4329, -0.5046, -0.3200]],\n",
       "\n",
       "        [[ 0.4907, -0.4465, -0.5670, -0.4019],\n",
       "         [ 0.4907, -0.4465, -0.5670, -0.4019]],\n",
       "\n",
       "        [[ 0.2298, -0.5656, -0.5439, -0.3680],\n",
       "         [ 0.2274, -0.5641, -0.5390, -0.3684]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 第二重：小网络优化——优化了效率\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfattentionV2(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 728) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.proj = nn.Linear(hidden_dim, hidden_dim * 3)\n",
    "\n",
    "        # self.querry_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # self.key_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # self.value_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x shape is :(batch, size_len, hidden_dim)\n",
    "        # QKV shape (batch, seq, hidden_dim* 3)\n",
    "        QKV = self.proj(x)\n",
    "        Q, K, V = torch.split(QKV, self.hidden_dim, hidden_dim = -1)\n",
    "\n",
    "        # Q = self.querry_proj(x)\n",
    "        # K = self.key_proj(x)\n",
    "        # V = self.value_proj(x)\n",
    "        #Q K V shape is :(batch, size_len, hidden_dim)\n",
    "\n",
    "\n",
    "        # attention_value 是： （batch, seq, seq）\n",
    "        attention_value = torch.matmul(\n",
    "            Q, K.transpose(-1,-2)\n",
    "        )\n",
    "\n",
    "        #attention_weight 是： （batch, seq, seq)\n",
    "        attention_weight = torch.softmax(\n",
    "            attention_value/ math.sqrt(self.hidden_dim),\n",
    "            dim = -1\n",
    "        )\n",
    "        print(attention_weight)\n",
    "\n",
    "        # (batch, seq, hidden_dim)\n",
    "        # output = torch.matmul(attention_weight, V)\n",
    "        output = attention_weight @ V\n",
    "        return output\n",
    "X = torch.rand(3, 2, 4)\n",
    "\n",
    "self_att_net = SelfattentionV1(4)\n",
    "self_att_net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4919, 0.5081],\n",
      "         [0.4974, 0.5026]],\n",
      "\n",
      "        [[0.5046, 0.4954],\n",
      "         [0.4994, 0.5006]],\n",
      "\n",
      "        [[0.5199, 0.4801],\n",
      "         [0.5378, 0.4622]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.6230e-02,  3.3549e-01, -4.3123e-01, -3.0909e-01],\n",
       "         [-8.7156e-02,  3.3572e-01, -4.3159e-01, -3.0822e-01]],\n",
       "\n",
       "        [[ 2.8140e-04,  4.4226e-01, -4.4176e-01, -1.9903e-01],\n",
       "         [ 2.8556e-03,  4.4375e-01, -4.4086e-01, -1.9829e-01]],\n",
       "\n",
       "        [[ 1.4999e-01,  5.8385e-01, -4.1191e-01, -1.8120e-01],\n",
       "         [ 1.5419e-01,  5.7938e-01, -4.1062e-01, -1.8692e-01]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 第三重：加入一些细节\n",
    "# 细节1：使用模型的时候会使用drop out \n",
    "# 细节2：每一个句子长度是不一样的，需要进行mask 掩码\n",
    "# 细节3：需要把output 矩阵，output_pojt,矩阵映射（可选）\n",
    "\n",
    "class slefattentionV3(nn.Module):\n",
    "    def __init__(self, dim, droupout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        self.proj = nn.Linear(dim, dim*3)\n",
    "        self.attention_dropout = nn.Dropout(self.droupout_rate)\n",
    "\n",
    "        #可选\n",
    "        self.output_proj = nn.Linear(dim, dim)\n",
    "    def forward(slef, x, attention_mask = None):\n",
    "        QKV = slef.proj(x)\n",
    "        Q, K, V = torch.split(QKV, self.dim, dim = -1)\n",
    "\n",
    "        attention_value = Q @ K.transpose(-1, -2)/math.sqrt(slef.dim)\n",
    "        if attention_mask is None:            \n",
    "            attention_value = attention_value.marked_fill(\n",
    "                attention_mask == 0,\n",
    "                float = \"-inf\"\n",
    "            )\n",
    "        \n",
    "        attention_weight = torch.softmax(\n",
    "            attention_weight,\n",
    "            dim = -1\n",
    "        )\n",
    "\n",
    "        attention_weight = slef.attention_dropout(attention_weight)\n",
    "        attention_result = attention_weight @ V\n",
    "\n",
    "        out_put = slef.output_proj(attention_result)\n",
    "\n",
    "X = torch.rand(3, 2, 4)\n",
    "\n",
    "self_att_net = SelfattentionV1(4)\n",
    "self_att_net(X)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
